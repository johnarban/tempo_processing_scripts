{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path, PosixPath\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# setup logging to file reorg_log.txt\n",
    "import logging\n",
    "\n",
    "\n",
    "# create logger with 'spam_application'\n",
    "logger = logging.getLogger('reorg')\n",
    "logger.setLevel(logging.INFO)\n",
    "# format\n",
    "formatter = logging.Formatter('%(levelname)s: %(message)s')\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler('reorg_log.txt')\n",
    "fh.setFormatter(formatter)\n",
    "fh.setLevel(logging.INFO)\n",
    "logger.addHandler(fh)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "ch.setLevel(logging.INFO)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "RUN = True\n",
    "\n",
    "\n",
    "def create_directory_structure(base_dir: Path, date: str) -> Path:\n",
    "    \"\"\"\n",
    "    Create the directory structure for the given date.\n",
    "    \"\"\"\n",
    "    day_dir = base_dir / date\n",
    "    if not day_dir.exists():\n",
    "        # pass\n",
    "        if RUN:\n",
    "            day_dir.mkdir(parents=True, exist_ok=False)\n",
    "        logger.info(f\"Created directory {day_dir}\")\n",
    "        # make subdirectories as well\n",
    "    if RUN:\n",
    "        subdirs = ['subsetted_netcdf','cloud_images/resized_images','images/resized_images']\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = day_dir / subdir\n",
    "            if not subdir_path.exists():\n",
    "                logger.info(f\"Created directory {subdir_path}\")\n",
    "                subdir_path.mkdir(parents=True, exist_ok=False)\n",
    "    \n",
    "    return day_dir\n",
    "\n",
    "def move_files_to_day_directory(base_dir: Path, in_dirs: list[Path], file_pattern: str, parser) -> None:\n",
    "    \"\"\"\n",
    "    Move files matching the file_pattern to their respective day directories.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for data_dir in in_dirs:\n",
    "        for file_path in data_dir.glob(file_pattern):\n",
    "            if file_path.is_file():\n",
    "                date = parser(file_path.name)\n",
    "                day_dir = create_directory_structure(base_dir, date)\n",
    "                new_path = day_dir / Path(*list(file_path.parts)[1:])\n",
    "                \n",
    "                if not new_path.exists():\n",
    "                    # check the directory exists\n",
    "                    if new_path.parent.exists():\n",
    "                        logger.info(f\"Moving {file_path} to {new_path}\")\n",
    "                        if RUN:\n",
    "                            shutil.move(str(file_path), str(new_path))\n",
    "                    else:\n",
    "                        if RUN:\n",
    "                            raise FileNotFoundError(f\"Directory {new_path.parent} does not exist.\")\n",
    "                        else:\n",
    "                            logger.error(f\"Directory {new_path.parent} does not exist.\")\n",
    "                        \n",
    "                else:\n",
    "                    pass\n",
    "                    # logger.error(f\"File already exists: original: {file_path} new: {new_path}\")\n",
    "                    # print(f\"File already exists:\\n\\t original: {file_path}\\n\\t new: {new_path}\")\n",
    "                \n",
    "                count += 1\n",
    "    print(f\"Moved {count} files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_dirs = [PosixPath('sep_23'),\n",
    " PosixPath('nov_17'),\n",
    " PosixPath('nov_25k'),\n",
    " PosixPath('nov_19'),\n",
    " PosixPath('nov_14b'),\n",
    " PosixPath('jul_10a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 0 files.\n",
      "Moved 0 files.\n",
      "Moved 0 files.\n",
      "Moved 0 files.\n",
      "Moved 0 files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ['subsetted_netcdf','cloud_images/resized_images','images/resized_images']\n",
    "base_dir = Path(\"./\")\n",
    "netcdf_pattern = \"./subsetted_netcdf/*.nc\"\n",
    "image_pattern = \"./images/*.png\"\n",
    "image_resized_pattern = \"./images/resized_images/*.png\"\n",
    "cloud_image_pattern = \"./cloud_images/*.png\"\n",
    "cloud_image_resized_pattern = \"./cloud_images/resized_images/*.png\"\n",
    "valid_directories = list(set(d.parent.parent for d in  Path(\"./\").glob('dec_*/subsetted_netcdf/*.nc')) - set(exclude_dirs))\n",
    "# valid_directories = [Path(\"may_01_onward\")]\n",
    "\n",
    "def netcdf_parser(filename: str) -> str:\n",
    "    date_str = filename.split('_')[-2]\n",
    "    return (datetime.strptime(date_str, \"%Y%m%dT%H%M%SZ\") - timedelta(hours=5)).strftime('%Y.%m.%d')\n",
    "# Move NetCDF files\n",
    "move_files_to_day_directory(base_dir, valid_directories, netcdf_pattern, parser=netcdf_parser)\n",
    "\n",
    "def image_parser(filename: str) -> str:\n",
    "    date_str = filename.split('_')[-1].split('.')[0]\n",
    "    return (datetime.strptime(date_str, \"%Y-%m-%dT%Hh%Mm\")- timedelta(hours=5)).strftime('%Y.%m.%d')\n",
    "# Move image files\n",
    "move_files_to_day_directory(base_dir, valid_directories, image_pattern, parser=image_parser)\n",
    "move_files_to_day_directory(base_dir, valid_directories, image_resized_pattern, parser=image_parser)\n",
    "move_files_to_day_directory(base_dir, valid_directories, cloud_image_pattern, parser=image_parser)\n",
    "move_files_to_day_directory(base_dir, valid_directories, cloud_image_resized_pattern, parser=image_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_directories =  list(set(d.parent.parent for d in  Path(\"./\").glob('dec_*/subsetted_netcdf/*.nc')) - set(exclude_dirs))\n",
    "list(valid_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_directories.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [] \n",
    "[d.extend(i.glob(cloud_image_resized_pattern)) for i in valid_directories];\n",
    "\n",
    "for i in d:\n",
    "    try:\n",
    "        image_parser(i.name)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
